{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nibabel as nib\n",
    "from utils import crop_image, generate_patient_info_brain, preprocess_brain\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info = generate_patient_info_brain(\"data/brain/structured/\", True)\n",
    "\n",
    "if not os.path.exists(\"data/brain/\"):\n",
    "    os.makedirs(\"data/brain/\")  \n",
    "np.save(os.path.join(\"data/brain/preprocessed/\", \"patient_info\"), patient_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_info = np.load(\"data/brain/preprocessed/patient_info.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.25  , 0.9375, 0.9375], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(np.array([patient_info[key][\"spacing\"] for key in patient_info.keys()]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataBrain = nib.load('data/brain/structured/patient001/image.nii.gz').get_fdata()\n",
    "dataHeart = nib.load('data/heart/training/patient001/patient001_frame01.nii.gz').get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"data/brain/structured/patient005/mask.nii.gz\"\n",
    "np.array(nib.load(fname).get_fdata().astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing patient 000\n",
      "Finished processing patient 010\n",
      "Finished processing patient 020\n",
      "Finished processing patient 030\n",
      "Finished processing patient 040\n",
      "Finished processing patient 050\n",
      "Finished processing patient 060\n",
      "Finished processing patient 070\n",
      "Finished processing patient 080\n",
      "Finished processing patient 090\n",
      "Finished processing patient 100\n",
      "Finished processing patient 110\n",
      "Finished processing patient 120\n",
      "Finished processing patient 130\n",
      "Finished processing patient 140\n",
      "Finished processing patient 150\n",
      "Finished processing patient 160\n",
      "Finished processing patient 170\n",
      "Finished processing patient 180\n",
      "Finished processing patient 190\n",
      "Finished processing patient 200\n",
      "Finished processing patient 210\n",
      "Finished processing patient 220\n",
      "Finished processing patient 230\n",
      "Finished processing patient 240\n",
      "Finished processing patient 250\n",
      "Finished processing patient 260\n",
      "Finished processing patient 270\n",
      "Finished processing patient 280\n",
      "Finished processing patient 290\n",
      "Finished processing patient 300\n",
      "Finished processing patient 310\n",
      "Finished processing patient 320\n",
      "Finished processing patient 330\n",
      "Finished processing patient 340\n",
      "Finished processing patient 350\n",
      "Finished processing patient 360\n",
      "Finished processing patient 370\n",
      "Finished processing patient 380\n",
      "Finished processing patient 390\n",
      "Finished processing patient 400\n",
      "Finished processing patient 410\n",
      "Finished processing patient 420\n",
      "Finished processing patient 430\n",
      "Finished processing patient 440\n"
     ]
    }
   ],
   "source": [
    "spacing_target = [10, 0.93, 0.93]\n",
    "\n",
    "if not os.path.exists(\"data/brain/preprocessed\"):\n",
    "    os.makedirs(\"data/brain/preprocessed\")\n",
    "    \n",
    "preprocess_brain(\n",
    "    range(0,444), patient_info, spacing_target,\n",
    "    \"data/brain/structured/\", \"data/brain/preprocessed\",\n",
    "    lambda folder, id: os.path.join(folder, 'patient{:03d}'.format(id)),\n",
    "    lambda : \"mask.nii.gz\",\n",
    "    skip=[9],\n",
    "    verbose=True\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torchvision\n",
    "from utils import AddPadding, CenterCrop, OneHot, ToTensor, MirrorTransform, SpatialTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = random.sample(range(1, 301), 50)\n",
    "train_ids = ids[:40]\n",
    "val_ids = ids[40:]\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    AddPadding((256,256)),\n",
    "    CenterCrop((256,256)),\n",
    "    OneHot(),\n",
    "    ToTensor()\n",
    "])\n",
    "transform_augmentation = torchvision.transforms.Compose([\n",
    "    MirrorTransform(),\n",
    "    SpatialTransform(patch_size=(256,256), angle_x=(-np.pi/6,np.pi/6), scale=(0.7,1.4), random_crop=True),\n",
    "    OneHot(),\n",
    "    ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    train_ids.remove(9)\n",
    "    # break\n",
    "except ValueError:\n",
    "    try:\n",
    "        val_ids.remove(9)\n",
    "    except ValueError:\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, importlib\n",
    "import CA\n",
    "importlib.reload(sys.modules['CA'])\n",
    "importlib.reload(sys.modules['utils'])\n",
    "\n",
    "import torch\n",
    "from CA import AE, plot_history, hyperparameter_tuning\n",
    "from utils import SYNDalaLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the following cell allows the user to tune his own hyperparameters. In case you wanna try our hyperparameters first, just skip this cell.\n",
    "\n",
    "#this is a list of possible values being tested for each hyperparameter.\n",
    "parameters = {\n",
    "    \"DA\": [True, False], #data augmentation\n",
    "    \"latent_size\": [100, 500], #size of the latent space of the autoencoder\n",
    "    \"BATCH_SIZE\": [8, 16, 4],\n",
    "    \"optimizer\": [torch.optim.Adam],\n",
    "    \"lr\": [2e-4, 1e-4, 1e-3],\n",
    "    \"weight_decay\": [1e-5],\n",
    "    \"tuning_epochs\": [5, 10], #number of epochs each configuration is run for\n",
    "    \"functions\": [[\"GDLoss\", \"MSELoss\"], [\"GDLoss\"], [\"BKGDLoss\", \"BKMSELoss\"]], #list of loss functions to be evaluated. BK stands for \"background\", which is a predominant and not compulsory class (it can lead to a dumb local minimum retrieving totally black images).\n",
    "    \"settling_epochs_BKGDLoss\": [10, 0], #during these epochs BK has half the weight of LV, RV and MYO in the evaluation of BKGDLoss\n",
    "    \"settling_epochs_BKMSELoss\": [10, 0], #during these epochs BK has half the weight of LV, RV and MYO in the evaluation of BKMSELoss\n",
    "}\n",
    "\n",
    "#this is a list of rules cutting out some useless combinations of hyperparameters from the tuning process.\n",
    "rules = [\n",
    "    '\"settling_epochs_BKGDLoss\" == 0 or \"BKGDLoss\" in \"functions\"',\n",
    "    '\"settling_epochs_BKMSELoss\" == 0 or \"BKMSELoss\" in \"functions\"',\n",
    "    '\"BKGDLoss\" not in \"functions\" or \"settling_epochs_BKGDLoss\" <= \"tuning_epochs\"',\n",
    "    '\"BKMSELoss\" not in \"functions\" or \"settling_epochs_BKMSELoss\" <= \"tuning_epochs\"',\n",
    "    #'\"BKGDLoss\" not in \"functions\" or \"settling_epochs_BKGDLoss\" >= \"settling_epochs_BKMSELoss\"'\n",
    "]\n",
    "\n",
    "optimal_parameters = hyperparameter_tuning(\n",
    "    parameters,\n",
    "    SYNDalaLoader(\"data/brain/preprocessed/\", patient_ids=train_ids, batch_size=None, transform=None),\n",
    "    SYNDalaLoader(\"data/brain/preprocessed/\", patient_ids=val_ids, batch_size=None, transform=None),\n",
    "    transform, transform_augmentation,\n",
    "    rules,\n",
    "    fast=True) #very important parameter. When False, all combinations are tested to return the one retrieving the maximum DSC. When True, the first combination avoiding dumb local minima is returned.\n",
    "\n",
    "\n",
    "np.save(os.path.join(\"data/brain/preprocessed/\", \"optimal_parameters\"), optimal_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE(\n",
      "  (encoder): Sequential(\n",
      "    (0): Conv2d(4, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (5): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): LeakyReLU(negative_slope=0.2)\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): Conv2d(32, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): LeakyReLU(negative_slope=0.2)\n",
      "    (19): Dropout(p=0.5, inplace=False)\n",
      "    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (21): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): LeakyReLU(negative_slope=0.2)\n",
      "    (23): Dropout(p=0.5, inplace=False)\n",
      "    (24): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (25): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): LeakyReLU(negative_slope=0.2)\n",
      "    (27): Dropout(p=0.5, inplace=False)\n",
      "    (28): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): LeakyReLU(negative_slope=0.2)\n",
      "    (31): Dropout(p=0.5, inplace=False)\n",
      "    (32): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (34): LeakyReLU(negative_slope=0.2)\n",
      "    (35): Dropout(p=0.5, inplace=False)\n",
      "    (36): Conv2d(32, 100, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): ConvTranspose2d(100, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): LeakyReLU(negative_slope=0.2)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): ConvTranspose2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): LeakyReLU(negative_slope=0.2)\n",
      "    (7): Dropout(p=0.5, inplace=False)\n",
      "    (8): ConvTranspose2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): LeakyReLU(negative_slope=0.2)\n",
      "    (11): Dropout(p=0.5, inplace=False)\n",
      "    (12): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): LeakyReLU(negative_slope=0.2)\n",
      "    (15): Dropout(p=0.5, inplace=False)\n",
      "    (16): ConvTranspose2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): LeakyReLU(negative_slope=0.2)\n",
      "    (19): Dropout(p=0.5, inplace=False)\n",
      "    (20): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (21): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): LeakyReLU(negative_slope=0.2)\n",
      "    (23): Dropout(p=0.5, inplace=False)\n",
      "    (24): ConvTranspose2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): LeakyReLU(negative_slope=0.2)\n",
      "    (27): Dropout(p=0.5, inplace=False)\n",
      "    (28): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (29): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (30): LeakyReLU(negative_slope=0.2)\n",
      "    (31): Dropout(p=0.5, inplace=False)\n",
      "    (32): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (33): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (34): LeakyReLU(negative_slope=0.2)\n",
      "    (35): Dropout(p=0.5, inplace=False)\n",
      "    (36): ConvTranspose2d(32, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (37): Softmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'preprocessed/training/patient_info.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [27], line 40\u001b[0m\n\u001b[1;32m     33\u001b[0m     start \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[39mprint\u001b[39m(ae)\n\u001b[1;32m     37\u001b[0m plot_history(\n\u001b[1;32m     38\u001b[0m     ae\u001b[39m.\u001b[39mtraining_routine(\n\u001b[1;32m     39\u001b[0m         \u001b[39mrange\u001b[39m(start, \u001b[39m100\u001b[39m),\n\u001b[0;32m---> 40\u001b[0m         SYNDalaLoader(\u001b[39m\"\u001b[39;49m\u001b[39mpreprocessed/training\u001b[39;49m\u001b[39m\"\u001b[39;49m, patient_ids\u001b[39m=\u001b[39;49mtrain_ids, batch_size\u001b[39m=\u001b[39;49mBATCH_SIZE, transform\u001b[39m=\u001b[39;49mtransform_augmentation \u001b[39mif\u001b[39;49;00m DA \u001b[39melse\u001b[39;49;00m transform),\n\u001b[1;32m     41\u001b[0m         SYNDalaLoader(\u001b[39m\"\u001b[39m\u001b[39mpreprocessed/training\u001b[39m\u001b[39m\"\u001b[39m, patient_ids\u001b[39m=\u001b[39mval_ids, batch_size\u001b[39m=\u001b[39mBATCH_SIZE, transform\u001b[39m=\u001b[39mtransform),\n\u001b[1;32m     42\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcheckpoints/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m )\n",
      "File \u001b[0;32m/home/thiry/quality_control_CMR/utils.py:319\u001b[0m, in \u001b[0;36mSYNDalaLoader.__init__\u001b[0;34m(self, root_dir, patient_ids, batch_size, transform)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m batch_size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    317\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatient_ids:\n\u001b[1;32m    318\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatient_loaders\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(\n\u001b[0;32m--> 319\u001b[0m             SYNPatient(root_dir, \u001b[39mid\u001b[39;49m, transform\u001b[39m=\u001b[39;49mtransform),\n\u001b[1;32m    320\u001b[0m             batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m\n\u001b[1;32m    321\u001b[0m         ))\n\u001b[1;32m    322\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcounter_id \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/home/thiry/quality_control_CMR/utils.py:361\u001b[0m, in \u001b[0;36mSYNPatient.__init__\u001b[0;34m(self, root_dir, patient_id, transform)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir \u001b[39m=\u001b[39m root_dir\n\u001b[1;32m    360\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mid \u001b[39m=\u001b[39m patient_id\n\u001b[0;32m--> 361\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(root_dir,\u001b[39m\"\u001b[39;49m\u001b[39mpatient_info.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m), allow_pickle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\u001b[39m.\u001b[39mitem()[patient_id]\n\u001b[1;32m    362\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39m=\u001b[39m transform\n",
      "File \u001b[0;32m/home/thiry/quality_control_CMR/.venv/lib/python3.8/site-packages/numpy/lib/npyio.py:390\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    388\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 390\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m    391\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    393\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocessed/training/patient_info.npy'"
     ]
    }
   ],
   "source": [
    "upload_your_own_parameters = False\n",
    "\n",
    "if upload_your_own_parameters:\n",
    "    optimal_parameters = np.load(os.path.join(\"data/brain/preprocessed\", \"optimal_parameters.npy\"), allow_pickle=True).item()\n",
    "else:\n",
    "    optimal_parameters = {\n",
    "        \"BATCH_SIZE\": 8,\n",
    "        \"DA\": False,\n",
    "        \"latent_size\": 100,\n",
    "        \"optimizer\": torch.optim.Adam,\n",
    "        \"lr\": 2e-4,\n",
    "        \"weight_decay\": 1e-5,\n",
    "        \"functions\": [\"BKGDLoss\", \"BKMSELoss\"],\n",
    "        \"settling_epochs_BKGDLoss\": 10,\n",
    "        \"settling_epochs_BKMSELoss\": 0\n",
    "    }\n",
    "    np.save(os.path.join(\"data/brain/preprocessed/\", \"optimal_parameters\"), optimal_parameters)\n",
    "\n",
    "assert optimal_parameters is not None, \"Be sure to continue with a working set of hyperparameters\"\n",
    "\n",
    "BATCH_SIZE = optimal_parameters[\"BATCH_SIZE\"]\n",
    "DA = optimal_parameters[\"DA\"]\n",
    "\n",
    "ae = AE(**optimal_parameters).to(device)\n",
    "\n",
    "ckpt = None\n",
    "if ckpt is not None:\n",
    "    ckpt = torch.load(ckpt)\n",
    "    ae.load_state_dict(ckpt[\"AE\"])\n",
    "    ae.optimizer.load_state_dict(ckpt[\"AE_optim\"])\n",
    "    start = ckpt[\"epoch\"]+1\n",
    "else:\n",
    "    start = 0\n",
    "\n",
    "print(ae)\n",
    "\n",
    "plot_history(\n",
    "    ae.training_routine(\n",
    "        range(start, 100),\n",
    "        SYNDalaLoader(\"data/brain/preprocessed/\", patient_ids=train_ids, batch_size=BATCH_SIZE, transform=transform_augmentation if DA else transform),\n",
    "        SYNDalaLoader(\"data/brain/preprocessed/\", patient_ids=val_ids, batch_size=BATCH_SIZE, transform=transform),\n",
    "        \"data/brain/checkpoints/\"\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26d733a98facd73c2412bf9332d44f71a6215b75d7e140b7f3987c8b99d7cfb5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
